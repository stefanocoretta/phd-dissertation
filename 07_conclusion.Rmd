# (PART) Conclusion {-}

# General discussion
\label{s:gen-disc}

This dissertation investigated the influence of consonant voicing on vowel duration by focussing on production aspects of vowel-consonant sequences.
As a cross-linguistic tendency, vowels are shorter when followed by voiceless consonants and longer when followed by voiced ones.
Several proposals as to what mechanisms underly this tendency have been proposed, but no account has won consensus.
Two studies were carried out to investigate durational and articulatory properties of vowels and consonants in Italian, Polish, and English.
Five papers presented and discussed the results from these studies.
Paper I and [...] show that the duration of the interval between the releases of the stops of a disyllabic word is not affected by the voicing of the second stop in Italian, Polish, and English.
On the other hand, the release-to-release interval of English monosyllabic words is longer when the second consonant is voiced.
The results in Paper [...] suggest the existence of a statistical correlation between vowel duration and degree of tongue root advancement, such that longer vowel durations correspond to greater tongue root advancement.
Finally, in Paper [...] it was speculated that the timing of the stop closure is modulated by the presence of emerging voiceless pre-aspiration, so that either enhancement of pre-aspiration delays closure or its prevention anticipates it.
This chapter provides an over-arching synthesis of the account proposed here in light of the observed patterns, and discusses the implications for theories of speech production.

## Gestural phasing

As argued in Paper [...], the temporal stability of the release-to-release interval is compatible with hypotheses about the gestural organisation of vowel and consonants within the domains of the syllable and the word.
According to the coupled oscillators model \citep{odell2008}, embedded in the task-dynamic model of Articulatory Phonology \citep{ohala1986a, browman1988, browman2000, goldstein2006, goldstein2014}, speech gestures can be implemented according to two coupling modes: in-phase (synchronous) or anti-phase (sequential) mode.
When two or more gestures are in an in-phase relation, they are initiated in synchrony.
If two or more gestures follow an anti-phase coupling mode, the gestures are implemented sequentially and one gesture starts when the preceding one has reached its target.
These two coupling modes can account for temporal aspects observed in the relative phasing of coda and onsets consonants with vowels.

<!-- TODO: cite Pouplier universal chapter -->
\citet{marin2010} showed that onset consonants in American English are in-phase with respect to the vowel nucleus and anti-phase with each other.
Such phasing pattern establishes a stable relationship between the centre of the consonant (or consonants in a cluster) and the following vowel.
Independent of the number of onset consonants, the temporal midpoint of the onset consonant(s) (the so-called 'C-centre') is maintained at a fixed distance from the vowel, such that an increasing number of consonants in the onset does not change the distance between the vowel and the onset C-centre (\Cref{fig:gorganisation}a).
On the other hand, coda consonants are in an anti-phase relation with the preceding vowel and between themselves.
When consonants are added to the coda, they are sequentially realised.
Temporal stability in codas is found in the lag between the vowel and the left-most edge of the coda, which is not affected by the number of coda consonants (\Cref{fig:gorganisation}b).
Other studies found further evidence for the synchronous and sequential coupling modes (see extensive review in \citealt{marin2010} and \citealt{marin2014}), although the use of one mode over the other depends on the language and the consonants under study [...].
Consonants can thus be said to follow either a C-centre or a left-edge organisation pattern depending on whether they are in-phase or anti-phase with the vocalic gesture.

Phasing modes are defined within the traditional syllable, or, in other words, relative to the tautosyllabic vowel (the following vowel for onsets and the preceding vowel for codas).
Less is known about the relation between heterosyllabic segments and how syllables are timed and phased within words.
\citet{ohman1967} and \citet{fowler1983} propose that vocalic gestures are implemented according to a rhythmic programme and that consonantal (constriction gestures) are superimposed to the vocalic gestural stream.
Furthermore, the authors argue that the timing of vocalic gestures follows a regular cyclic pattern, which is in turn responsible for the rhythmic patterns of speech.
\citet{fowler1983} reviews a collection of findings from speech production, perception, and phonological studies that support the idea of the cyclic production of vowels.

A consequence of the cyclic production of vowels and the independence of the vocalic and consonantal gestures is that two consecutive vowels within a word would be at a stable temporal distance independent of the nature and number of the intervening consonants.
This hypothesis, however, is not borne out by the empirical evidence in \citet{zmarich2011} and \citet{zeroual2015}.
Using electromagnetic articulography, both studies find that the distance between two vowels is greater when the intervening consonant is a geminate compared to when it is a singleton consonant.
\citet{de-jong1991} finds only partial support for the independence of vowels and consonants.
These studies also find substantial inter-speaker variation in the particulars of the gestural implementation of vowel-consonant sequences.

While the strong prediction of vowel-to-vowel isochrony is not confirmed by data comparing singleton and geminates, it is possible that a softer formulation would still work.
A possible reason for why the isochrony breaks in that context is that the geminate consonant is a blend of two phasing patterns.
For example, \citet{zeroual2015} argue that their findings support the interpretation of geminates as two identical consonants produced sequentially.
This would mean that the first part of the geminate is implemented anti-phase with the preceding vowel, while the second part is articulated in-phase with the following.
The presence of an anti-phase gesture intervening between the vowels could be responsible for the disruption of the vowel-to-vowel isochrony.
If this is the case, then isochrony would apply only in those cases where the intervening consonants are in-phase with the second vowel (a more detailed account and an alternative account are discussed in [...]).

Turning to the voicing contrast, since CVCV words differing in the voicing of C2 just include a singleton consonant, we can expect VV isochrony to apply.
Since onset consonants are in-phase with the tautosyllabic vowel and the timing of the release of C2 is not affected by voicing, the timing of the gestural onset of voiceless and voiced stops should also be identical.
<!-- TODO: schematics -->
This is in part confirmed by the ultrasound tongue imaging data of Study I.
<!-- TODO: GONS appendix -->
The duration of the interval between the acoustic release of C1 and the gestural onset time of C2 is not affected by the voicing status of C2.
On the other hand, the velocity of the closing gesture is known to differ \citep{van-summers1987}.
<!-- TODO: say that velocity data are not good here? -->
While the gestural onset is identical, the difference in closing velocity produces the acoustic pattern of the differential in VC boundary timing.
Fast closing velocity in voiceless stops creates an early VC boundary, while a slow closing gesture generates a late VC boundary.

On the other hand, in tautosyllabic VC sequences, the consonant gesture is implemented anti-phase with the preceding vowel, meaning that the gestures are produced sequentially.
In such case, VV isochrony is broken and the duration of V1 can be modulated freely.
This is what it is argued to happen in monosyllabic words, where the distance between the releases of C1 and C2 differs depending on the voicing of C2.
\citet{de-jong2002} indeed finds that in English monosyllabic words not only the velocity of the closing gesture differs, but also the timing of the consonant gesture, which happens later within the vowel in the context of voiced stops.

## One account to rule them all

The results of Study I and II taken together allow for the formulation of an account of the voicing effect that brings together aspects of compensation and timing as proposed by different accounts.
Two important aspects of the account proposed here is the temporal stability of the stop releases and the timing of the VC boundary.
The temporal stability is one fundamental aspect of the compensatory temporal adjustment account.
The difference between this and the account proposed here is that in the former closure duration determines the duration of the preceding vowel.
In the present account, a rather more neutral position is taken.
The timing of the VC boundary within the release-to-release interval determines the durations of *both* the vowel and closure.
On the other hand, the timing of the VC boundary is modulated by aspects that would fall under the laryngeal adjustments and the rate of closure accounts.

The ultrasound and EGG study, as discussed in Papers [...] and [...], suggest that mechanisms independent from closure duration per se can act upon the timing of the VC boundary and, indirectly, on the duration of closure.
For one, tongue root position might drive the timing of the boundary by delaying it to allow for greater tongue root advancement.
As discussed in Paper [...], tongue root advancement is known to facilitate voicing during the production of the stop closure.
Second, the development of pre-aspiration could also influence the timing of the VC boundary by delaying or anticipating it depending on whether pre-aspiration is enhanced or prevented.

Moreover, the account proposed here is diachronic in nature, in as much as it reveals a possible diachronic pathway to the emergence of the difference in vowel duration rooted in production aspects of vowels and consonants.
In particular, I argue that the voicing effect can emerge because of the temporal stability of CVC sequences and the differences in timing of the closure in voiceless and voiced stops.
Such an account assumes that the original scenario is one in which the duration of vowels and that of closures do not differ.
Speakers start producing the difference via developmental learning or historical change.
On top of this, when VV isochrony does not constrain the temporal distances in CVC sequences, vowel and closure durations are free to be manipulated independently with the aim of manipulating the VC ratio, as argued by perceptual accounts of the voicing effect.

While the account proposed here is based on production mechanisms, it cannot be completely excluded that the production differences observed and stipulated here are actually consequential to perceptual biases.
In this alternative scenario, there could be a design feature of the perceptual system that generates the differential duration percept even when there is not such difference in the acoustic output/input.
An example from the domain of vision illustrates this possibility.
When looking at a wheel spinning in clockwise direction, the observer will start seeing the wheel rotating counter-clockwise when the rotation speed exceeds a threshold.
There is nothing in the mechanics of a wheel spinning around its axis that can explain this perceptual fact.
Rather, the human brain is a design feature (rate of visual perception update) that creates the illusion of the wheel spinning in the opposite direction.
In this case, since the wheel and its percept are two separate realities, the latter does not change how the wheel is spinning in reality.
In the case of speech, however, a bias of the the perceptual system does generally spill onto production.

Teasing apart production and perceptual mechanisms in speech is more difficult than in the spinning wheel case since production and perception operate on the same ontological reality, i.e. speech.
On the other hand, when independent physical explanations behind production biases or mechanisms can be pointed out, it can be assumed that they can be considered design features of the production system and not just consequences of a perceptual bias.
In this case, we could assume that, while perceptual biases can pick up on the duration difference of vowels as a cue to voicing and enhance such contrast, the differences emerge from a production mechanism in the first place.

## Cross-linguistic differences

As discussed in [...], the degree of the voicing effect is generally thought to vary depending on the language.
It is generally said that English has the bigger effect, while it is smaller in Italian and possibly absent in Polish.
Papers [...] and [...] indicate a somewhat less systematic difference between these languages.
While direct comparison is not straightforward given the different material used in Study I and II, I ran a Bayesian analysis of the effect of voicing in disyllabic words comparing English, Italian, and Polish (see Appendix [...]).
The analysis suggests that, when controlling for differences in average baseline vowel duration and speech rate, there is no strong evidence for a difference in the effect of voicing across these languages.
Crucially, there is indication that the effect differs in monosyllabic vs disyllabic words, and that it is greater in the former.
So comparison across languages should be done properly across the same contexts.
This was done by \citet{laeufer1992}, who shows that the effect becomes comparable when the duration of the vowel is comparable.

Moreover, the results from the Bayesian meta-analysis of the English voicing effect (Appendix [...]) indicates that, while there is clearly a positive effect of voicing on vowel duration, less can be said about the magnitude of such effect.
The estimated range of values is between 55 and 95 ms, however the analysis revealed a possibility for publication bias in favour of larger effects.
Note also that there could be differences in speech rate, and older studies might have produced data at lower rates.
The smaller effect found in Study II could be indicative of such differences.
For example, the intercept estimate of vowel duration before voiceless stops is about 125 ms in Study II but the average duration in the meta-analytical data is 150 ms.
Although the voicing effect does not scale linearly with vowel duration, as suggested by \citet{ko2018}, slower speech rates (i.e. longer vowel durations) correspond to a greater effect of voicing.

I am not claiming however, that the voicing effect must be universal across the board.
Especially in the case of monosyllabic words, as argued above, language-specific perceptual enhancement can modulate the magnitude.
For example, \citet{tanner2019} demonstrate that, although not unambiguously, the effect in monosyllabic words differs across varieties of English.
They also argue that the effect they found in spontaneous speech is smaller than that of the laboratory speech reported in previous studies.
However, when their results are compared to those of Study II, the difference is substantially reduced.
The ratio of the difference in vowel duration in \citet{tanner2019} is estimated to be between 1 and 1.16.
The ratio in Study II is between 1.03 and 1.17, a range that is virtually identical to that of \citet{tanner2019}.

# Final thoughts

The use of nonce words could be seen as detrimental due to the their unnaturalness.
However, using nonce words has the perk of facilitating experimental design and control over phonological factors.
Note that the effects found here are built according to analogical processes based on stored exemplars and/or abstract representations.
Hence, even if unnatural speech was used, these studies have tapped into the speakers' knowledge, though somewhat indirectly.
Moreover, nonce words eliminate issues relating to lexical frequency, which can substantially affect results.
On the other hand, neighbourhood density is not controlled for, and this might still exercise an influence on the phonetic effects sought for in this dissertation.
It is desirable that future work investigates the patterns observed in nonce words using real words, while carefully controlling for lexical frequency and neighbourhood density, among other usage factors.

A limitation of the studies in this work is related to statistical precision of the effect estimates.
As discussed in several places, some of the effects have quite large confidence/credible intervals.
In some cases, like in the cross-linguistic comparative analysis of the voicing effect, it is difficult to draw any certain conclusion.
Much of this uncertainty derives from the sample sizes employed in these studies.
Although the number of speakers included is generally equal or above average (see ...), the number of observations is not at times sufficient enough to reach an appreciable precision.
The results discussed in this dissertation stress how important obtaining a sufficient sample is, especially when dealing with small effect sizes.
Much of the phonetic literature relies on small sample sizes, but most work is done on data which is generally quite noisy.
Note also that arguments of magnitude are very often used to make theoretical statements about what constitute a relevant effect.
However, reasoning on theoretical relevance of effect sizes is probably currently biased, and most of phonetics and phonological theory makes qualitative rather than precise quantitative predictions.

Thresholds based on just noticeable differences also have their limits.
\citet{huggins1972} for example shows that the perceptual threshold for segment durations varies depending on the type and baseline duration of the segment.
For example, for a 90 ms vowel, speakers can reliably detect differences of 5 ms.
Moreover, as ... say, such thresholds could be relevant only within the task they have been elicited in, and in more natural contexts even smaller differences could be perceptible in conjunction with other, possibly more robust, cues.
Until we can establish with certainty what differences in which contexts are physiologically impossible to be perceived, an alternative solution could be to use measurement precision as a threshold.
For example, \citet{allen1978} shows that the 95% confidence intervals of vowels measured by accurate phoneticians ranges between 10 and 25 ms.
We could take the smallest value (10 ms) as representative of a region of practical equivalence (see ...).
Differences below 5 ms would be masked by noise and more difficult to be detected.
On the other hand, \citet{begus2017} reports very small standard errors, even below 1 ms.
In sum, our current knowledge of perceptible and measurable differences is limited, and future work should focus on investigating both in light of theoretical and practical considerations.

This dissertation focussed on the voicing effect of stop consonants, but other manners of articulation participate in the effect.
According to the compensatory account presented here, a greater difference in consonant duration should correspond to a greater voicing effect.
For example, \citet{crystal1988} report a greater difference in fricative duration than in stop duration, which would be compatible with a greater voicing effect in the former.
However, while \citet{house1953} and \citet{peterson1960} find that the effect is greater in fricatives than in stops, \citet{tanner2019} observe the opposite trend.
Future work should directly test the relation between differences in consonant duration and the voicing effect with consonants belonging to different manners of articulation.


# (PART) Appendices {-}
